
 Average loss:  0.40500837564468384  --- Iterations:  8  --- Epochs:  1
/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
 Average loss:  0.29533419013023376  --- Iterations:  16  --- Epochs:  1
 Average loss:  0.22698551416397095  --- Iterations:  24  --- Epochs:  1
 Average loss:  0.18502084910869598  --- Iterations:  32  --- Epochs:  1
 Average loss:  0.15554741024971008  --- Iterations:  40  --- Epochs:  1
 Average loss:  0.13442236185073853  --- Iterations:  48  --- Epochs:  1
 Average loss:  0.11891181766986847  --- Iterations:  56  --- Epochs:  1
 Average loss:  0.10671824216842651  --- Iterations:  64  --- Epochs:  1
 Average loss:  0.09687874466180801  --- Iterations:  72  --- Epochs:  1
 Average loss:  0.08882752805948257  --- Iterations:  80  --- Epochs:  1
 Average loss:  0.08190608024597168  --- Iterations:  88  --- Epochs:  1
 Average loss:  0.07633444666862488  --- Iterations:  96  --- Epochs:  1
 Average loss:  0.07134809345006943  --- Iterations:  104  --- Epochs:  1
 Average loss:  0.06707558035850525  --- Iterations:  112  --- Epochs:  1
 Average loss:  0.06338490545749664  --- Iterations:  120  --- Epochs:  1
 Average loss:  0.060107968747615814  --- Iterations:  128  --- Epochs:  1
 Average loss:  0.05710214376449585  --- Iterations:  136  --- Epochs:  1
 Average loss:  0.05434760823845863  --- Iterations:  144  --- Epochs:  1
 Average loss:  0.05194573849439621  --- Iterations:  152  --- Epochs:  1
 Average loss:  0.049746524542570114  --- Iterations:  160  --- Epochs:  1
 Average loss:  0.04783044010400772  --- Iterations:  168  --- Epochs:  1
 Average loss:  0.04597817361354828  --- Iterations:  176  --- Epochs:  1
 Average loss:  0.0443301796913147  --- Iterations:  184  --- Epochs:  1
 Average loss:  0.04278526455163956  --- Iterations:  192  --- Epochs:  1
 Average loss:  0.041254136711359024  --- Iterations:  200  --- Epochs:  1
 Average loss:  0.03991394490003586  --- Iterations:  208  --- Epochs:  1
 Average loss:  0.03863946348428726  --- Iterations:  216  --- Epochs:  1
 Average loss:  0.037487901747226715  --- Iterations:  224  --- Epochs:  1
 Average loss:  0.036402083933353424  --- Iterations:  232  --- Epochs:  1
 Average loss:  0.035360511392354965  --- Iterations:  240  --- Epochs:  1
 Average loss:  0.034380633383989334  --- Iterations:  248  --- Epochs:  1
 Average loss:  0.03349805250763893  --- Iterations:  256  --- Epochs:  1
 Average loss:  0.032659415155649185  --- Iterations:  264  --- Epochs:  1
 Average loss:  0.031858816742897034  --- Iterations:  272  --- Epochs:  1
 Average loss:  0.031090768054127693  --- Iterations:  280  --- Epochs:  1
 Average loss:  0.030373496934771538  --- Iterations:  288  --- Epochs:  1
 Average loss:  0.02971002645790577  --- Iterations:  296  --- Epochs:  1
 Average loss:  0.029058456420898438  --- Iterations:  304  --- Epochs:  1
 Average loss:  0.028422793373465538  --- Iterations:  312  --- Epochs:  1
 Average loss:  0.027823418378829956  --- Iterations:  320  --- Epochs:  1
 Average loss:  0.027228552848100662  --- Iterations:  328  --- Epochs:  1
 Average loss:  0.02665768191218376  --- Iterations:  336  --- Epochs:  1
 Average loss:  0.02613123133778572  --- Iterations:  344  --- Epochs:  1
 Average loss:  0.025651006028056145  --- Iterations:  352  --- Epochs:  1
 Average loss:  0.025155777111649513  --- Iterations:  360  --- Epochs:  1
 Average loss:  0.024665944278240204  --- Iterations:  368  --- Epochs:  1
 Average loss:  0.024223750457167625  --- Iterations:  376  --- Epochs:  1
 Average loss:  0.023812569677829742  --- Iterations:  384  --- Epochs:  1
 Average loss:  0.02338588237762451  --- Iterations:  392  --- Epochs:  1
 Average loss:  0.02300347574055195  --- Iterations:  400  --- Epochs:  1
 Average loss:  0.02259565144777298  --- Iterations:  408  --- Epochs:  1
 Average loss:  0.0222273338586092  --- Iterations:  416  --- Epochs:  1
 Average loss:  0.021863127127289772  --- Iterations:  424  --- Epochs:  1
 Average loss:  0.021551713347434998  --- Iterations:  432  --- Epochs:  1
 Average loss:  0.021230923011898994  --- Iterations:  440  --- Epochs:  1
 Average loss:  0.02090691402554512  --- Iterations:  448  --- Epochs:  1
 Average loss:  0.020591894164681435  --- Iterations:  456  --- Epochs:  1
 Average loss:  0.020294956862926483  --- Iterations:  464  --- Epochs:  1
 Average loss:  0.019998248666524887  --- Iterations:  472  --- Epochs:  1
 Average loss:  0.019702835008502007  --- Iterations:  480  --- Epochs:  1
 Average loss:  0.01944521814584732  --- Iterations:  488  --- Epochs:  1
 Average loss:  0.01918184384703636  --- Iterations:  496  --- Epochs:  1
 Average loss:  0.01895490288734436  --- Iterations:  504  --- Epochs:  1
 Average loss:  0.01871323026716709  --- Iterations:  512  --- Epochs:  1
 Average loss:  0.018473481759428978  --- Iterations:  520  --- Epochs:  1
 Average loss:  0.01827116869390011  --- Iterations:  528  --- Epochs:  1
 Average loss:  0.018054617568850517  --- Iterations:  536  --- Epochs:  1
 Average loss:  0.017849978059530258  --- Iterations:  544  --- Epochs:  1
 Average loss:  0.01765170320868492  --- Iterations:  552  --- Epochs:  1
 Average loss:  0.017442192882299423  --- Iterations:  560  --- Epochs:  1
 Average loss:  0.01724329963326454  --- Iterations:  568  --- Epochs:  1
 Average loss:  0.017041752114892006  --- Iterations:  576  --- Epochs:  1
 Average loss:  0.01686583273112774  --- Iterations:  584  --- Epochs:  1
 Average loss:  0.016689971089363098  --- Iterations:  592  --- Epochs:  1
 Average loss:  0.016501346603035927  --- Iterations:  600  --- Epochs:  1
 Average loss:  0.01631202921271324  --- Iterations:  608  --- Epochs:  1
 Average loss:  0.01613975502550602  --- Iterations:  616  --- Epochs:  1
 Average loss:  0.01599002629518509  --- Iterations:  624  --- Epochs:  1
 Average loss:  0.01583261229097843  --- Iterations:  632  --- Epochs:  1
 Average loss:  0.01566213183104992  --- Iterations:  640  --- Epochs:  1
 Average loss:  0.015501146204769611  --- Iterations:  648  --- Epochs:  1
 Average loss:  0.015356031246483326  --- Iterations:  656  --- Epochs:  1
 Average loss:  0.015227909199893475  --- Iterations:  664  --- Epochs:  1
 Average loss:  0.015069893561303616  --- Iterations:  672  --- Epochs:  1
 Average loss:  0.014914651401340961  --- Iterations:  680  --- Epochs:  1
 Average loss:  0.014800145290791988  --- Iterations:  688  --- Epochs:  1
 Average loss:  0.014661001972854137  --- Iterations:  696  --- Epochs:  1
 Average loss:  0.014520464465022087  --- Iterations:  704  --- Epochs:  1
 Average loss:  0.014390507712960243  --- Iterations:  712  --- Epochs:  1
 Average loss:  0.014262925833463669  --- Iterations:  720  --- Epochs:  1
 Average loss:  0.014170997776091099  --- Iterations:  728  --- Epochs:  1
 Average loss:  0.014063122682273388  --- Iterations:  736  --- Epochs:  1
 Average loss:  0.013943209312856197  --- Iterations:  744  --- Epochs:  1
 Average loss:  0.01383178774267435  --- Iterations:  752  --- Epochs:  1
 Average loss:  0.013720986433327198  --- Iterations:  760  --- Epochs:  1
 Average loss:  0.013640153221786022  --- Iterations:  768  --- Epochs:  1
 Average loss:  0.013536450453102589  --- Iterations:  776  --- Epochs:  1
 Average loss:  0.013423464260995388  --- Iterations:  784  --- Epochs:  1
 Average loss:  0.013310735113918781  --- Iterations:  792  --- Epochs:  1
 Average loss:  0.01321424450725317  --- Iterations:  800  --- Epochs:  1
 Average loss:  0.013108842074871063  --- Iterations:  808  --- Epochs:  1
 Average loss:  0.01301671378314495  --- Iterations:  816  --- Epochs:  1
 Average loss:  0.012918787077069283  --- Iterations:  824  --- Epochs:  1
 Average loss:  0.012822127901017666  --- Iterations:  832  --- Epochs:  1
 Average loss:  0.012742551974952221  --- Iterations:  840  --- Epochs:  1
 Average loss:  0.012654914520680904  --- Iterations:  848  --- Epochs:  1
 Average loss:  0.012575387954711914  --- Iterations:  856  --- Epochs:  1
 Average loss:  0.012485919520258904  --- Iterations:  864  --- Epochs:  1
 Average loss:  0.012394724413752556  --- Iterations:  872  --- Epochs:  1
 Average loss:  0.012299754656851292  --- Iterations:  880  --- Epochs:  1
 Average loss:  0.01220728363841772  --- Iterations:  888  --- Epochs:  1
 Average loss:  0.012128413654863834  --- Iterations:  896  --- Epochs:  1
 Average loss:  0.012053071521222591  --- Iterations:  904  --- Epochs:  1
 Average loss:  0.011964892037212849  --- Iterations:  912  --- Epochs:  1
 Average loss:  0.01189073920249939  --- Iterations:  920  --- Epochs:  1
 Average loss:  0.011814627796411514  --- Iterations:  928  --- Epochs:  1
 Average loss:  0.011743852868676186  --- Iterations:  936  --- Epochs:  1
 Average loss:  0.01166886929422617  --- Iterations:  944  --- Epochs:  1
 Average loss:  0.011601782403886318  --- Iterations:  952  --- Epochs:  1
 Average loss:  0.011533144861459732  --- Iterations:  960  --- Epochs:  1
 Average loss:  0.011460493318736553  --- Iterations:  968  --- Epochs:  1
 Average loss:  0.011391449719667435  --- Iterations:  976  --- Epochs:  1
 Average loss:  0.011324869468808174  --- Iterations:  984  --- Epochs:  1
 Average loss:  0.011255132034420967  --- Iterations:  992  --- Epochs:  1
 Average loss:  0.011184955947101116  --- Iterations:  1000  --- Epochs:  1
 Average loss:  0.011113079264760017  --- Iterations:  1008  --- Epochs:  1
 Average loss:  0.011044343002140522  --- Iterations:  1016  --- Epochs:  1
 Average loss:  0.010987107641994953  --- Iterations:  1024  --- Epochs:  1
 Average loss:  0.010919561609625816  --- Iterations:  1032  --- Epochs:  1
 Average loss:  0.010855152271687984  --- Iterations:  1040  --- Epochs:  1
 Average loss:  0.010798822157084942  --- Iterations:  1048  --- Epochs:  1
 Average loss:  0.010752256028354168  --- Iterations:  1056  --- Epochs:  1
 Average loss:  0.010696973651647568  --- Iterations:  1064  --- Epochs:  1
 Average loss:  0.010656501166522503  --- Iterations:  1072  --- Epochs:  1
 Average loss:  0.010609157383441925  --- Iterations:  1080  --- Epochs:  1
 Average loss:  0.01056397520005703  --- Iterations:  1088  --- Epochs:  1
 Average loss:  0.010511784814298153  --- Iterations:  1096  --- Epochs:  1
 Average loss:  0.010462528094649315  --- Iterations:  1104  --- Epochs:  1
 Average loss:  0.01041523925960064  --- Iterations:  1112  --- Epochs:  1
 Average loss:  0.010361948050558567  --- Iterations:  1120  --- Epochs:  1
 Average loss:  0.010313429869711399  --- Iterations:  1128  --- Epochs:  1
 Average loss:  0.0102540859952569  --- Iterations:  1136  --- Epochs:  1
 Average loss:  0.010201875120401382  --- Iterations:  1144  --- Epochs:  1
 Average loss:  0.010155697353184223  --- Iterations:  1152  --- Epochs:  1
 Average loss:  0.010101835243403912  --- Iterations:  1160  --- Epochs:  1
 Average loss:  0.010052304714918137  --- Iterations:  1168  --- Epochs:  1
 Average loss:  0.01000168826431036  --- Iterations:  1176  --- Epochs:  1
 Average loss:  0.009962807409465313  --- Iterations:  1184  --- Epochs:  1
 Average loss:  0.0099125225096941  --- Iterations:  1192  --- Epochs:  1
 Average loss:  0.00987095758318901  --- Iterations:  1200  --- Epochs:  1
 Average loss:  0.009825708344578743  --- Iterations:  1208  --- Epochs:  1
 Average loss:  0.009786236099898815  --- Iterations:  1216  --- Epochs:  1
 Average loss:  0.00973644107580185  --- Iterations:  1224  --- Epochs:  1
 Average loss:  0.00970293115824461  --- Iterations:  1232  --- Epochs:  1
 Average loss:  0.009659995324909687  --- Iterations:  1240  --- Epochs:  1
 Average loss:  0.009608563035726547  --- Iterations:  1248  --- Epochs:  1
 Average loss:  0.009565731510519981  --- Iterations:  1256  --- Epochs:  1
 Average loss:  0.009518781676888466  --- Iterations:  1264  --- Epochs:  1
 Average loss:  0.009478163905441761  --- Iterations:  1272  --- Epochs:  1
 Average loss:  0.009434901177883148  --- Iterations:  1280  --- Epochs:  1
 Average loss:  0.009390851482748985  --- Iterations:  1288  --- Epochs:  1
 Average loss:  0.009376143105328083  --- Iterations:  1296  --- Epochs:  1
 Average loss:  0.00934212002903223  --- Iterations:  1304  --- Epochs:  1
 Average loss:  0.009309553541243076  --- Iterations:  1312  --- Epochs:  1
 Average loss:  0.009268208406865597  --- Iterations:  1320  --- Epochs:  1
 Average loss:  0.009242106229066849  --- Iterations:  1328  --- Epochs:  1
 Average loss:  0.00920221209526062  --- Iterations:  1336  --- Epochs:  1
 Average loss:  0.009167080745100975  --- Iterations:  1344  --- Epochs:  1
 Average loss:  0.009132570587098598  --- Iterations:  1352  --- Epochs:  1
 Average loss:  0.009093213826417923  --- Iterations:  1360  --- Epochs:  1
 Average loss:  0.009059437550604343  --- Iterations:  1368  --- Epochs:  1
 Average loss:  0.009019906632602215  --- Iterations:  1376  --- Epochs:  1
 Average loss:  0.008980321697890759  --- Iterations:  1384  --- Epochs:  1
 Average loss:  0.00894941296428442  --- Iterations:  1392  --- Epochs:  1
 Average loss:  0.008922405540943146  --- Iterations:  1400  --- Epochs:  1
 Average loss:  0.008890044875442982  --- Iterations:  1408  --- Epochs:  1
 Average loss:  0.008853273466229439  --- Iterations:  1416  --- Epochs:  1
 Average loss:  0.008817530237138271  --- Iterations:  1424  --- Epochs:  1
 Average loss:  0.00878396350890398  --- Iterations:  1432  --- Epochs:  1
 Average loss:  0.008761163800954819  --- Iterations:  1440  --- Epochs:  1
 Average loss:  0.008732758462429047  --- Iterations:  1448  --- Epochs:  1
 Average loss:  0.008698015473783016  --- Iterations:  1456  --- Epochs:  1
 Average loss:  0.008665318600833416  --- Iterations:  1464  --- Epochs:  1
 Average loss:  0.008633111603558064  --- Iterations:  1472  --- Epochs:  1
 Average loss:  0.008603688329458237  --- Iterations:  1480  --- Epochs:  1
 Average loss:  0.00857613980770111  --- Iterations:  1488  --- Epochs:  1
 Average loss:  0.008543103002011776  --- Iterations:  1496  --- Epochs:  1
 Average loss:  0.008531693369150162  --- Iterations:  1504  --- Epochs:  1
 Average loss:  0.008501618169248104  --- Iterations:  1512  --- Epochs:  1
 Average loss:  0.008473089896142483  --- Iterations:  1520  --- Epochs:  1
 Average loss:  0.008442575111985207  --- Iterations:  1528  --- Epochs:  1
 Average loss:  0.008411458693444729  --- Iterations:  1536  --- Epochs:  1
 Average loss:  0.008380196988582611  --- Iterations:  1544  --- Epochs:  1
 Average loss:  0.008355198428034782  --- Iterations:  1552  --- Epochs:  1
 Average loss:  0.008328729309141636  --- Iterations:  1560  --- Epochs:  1
 Average loss:  0.008298767730593681  --- Iterations:  1568  --- Epochs:  1
 Average loss:  0.00827267300337553  --- Iterations:  1576  --- Epochs:  1
 Average loss:  0.008254414424300194  --- Iterations:  1584  --- Epochs:  1
 Average loss:  0.008227946236729622  --- Iterations:  1592  --- Epochs:  1
 Average loss:  0.008203642442822456  --- Iterations:  1600  --- Epochs:  1
 Average loss:  0.008179852738976479  --- Iterations:  1608  --- Epochs:  1
 Average loss:  0.008158965036273003  --- Iterations:  1616  --- Epochs:  1
 Average loss:  0.008133815601468086  --- Iterations:  1624  --- Epochs:  1
 Average loss:  0.008109461516141891  --- Iterations:  1632  --- Epochs:  1
 Average loss:  0.00808124989271164  --- Iterations:  1640  --- Epochs:  1
 Average loss:  0.008052175864577293  --- Iterations:  1648  --- Epochs:  1
 Average loss:  0.008021070621907711  --- Iterations:  1656  --- Epochs:  1
 Average loss:  0.007997900247573853  --- Iterations:  1664  --- Epochs:  1
 Average loss:  0.007975379005074501  --- Iterations:  1672  --- Epochs:  1
 Average loss:  0.00794856995344162  --- Iterations:  1680  --- Epochs:  1
 Average loss:  0.007926108315587044  --- Iterations:  1688  --- Epochs:  1
 Average loss:  0.007904250174760818  --- Iterations:  1696  --- Epochs:  1
 Average loss:  0.007880251854658127  --- Iterations:  1704  --- Epochs:  1
 Average loss:  0.007850078865885735  --- Iterations:  1712  --- Epochs:  1
 Average loss:  0.007827202789485455  --- Iterations:  1720  --- Epochs:  1
 Average loss:  0.00780534790828824  --- Iterations:  1728  --- Epochs:  1
 Average loss:  0.007780910469591618  --- Iterations:  1736  --- Epochs:  1
 Average loss:  0.00776187889277935  --- Iterations:  1744  --- Epochs:  1
 Average loss:  0.0077360584400594234  --- Iterations:  1752  --- Epochs:  1
 Average loss:  0.0077149090357124805  --- Iterations:  1760  --- Epochs:  1
 Average loss:  0.007695040665566921  --- Iterations:  1768  --- Epochs:  1
 Average loss:  0.007673329673707485  --- Iterations:  1776  --- Epochs:  1
 Average loss:  0.007659802678972483  --- Iterations:  1784  --- Epochs:  1
 Average loss:  0.007646583952009678  --- Iterations:  1792  --- Epochs:  1
 Average loss:  0.007621274795383215  --- Iterations:  1800  --- Epochs:  1
 Average loss:  0.007598117459565401  --- Iterations:  1808  --- Epochs:  1
 Average loss:  0.00758047541603446  --- Iterations:  1816  --- Epochs:  1
 Average loss:  0.007556771859526634  --- Iterations:  1824  --- Epochs:  1
 Average loss:  0.007533940486609936  --- Iterations:  1832  --- Epochs:  1
 Average loss:  0.007516833487898111  --- Iterations:  1840  --- Epochs:  1
 Average loss:  0.007501937914639711  --- Iterations:  1848  --- Epochs:  1
 Average loss:  0.0074798958376049995  --- Iterations:  1856  --- Epochs:  1
 Average loss:  0.007456154562532902  --- Iterations:  1864  --- Epochs:  1
 Average loss:  0.007439087610691786  --- Iterations:  1872  --- Epochs:  1
 Average loss:  0.0074170795269310474  --- Iterations:  1880  --- Epochs:  1
 Average loss:  0.0073961359448730946  --- Iterations:  1888  --- Epochs:  1
 Average loss:  0.0073796287178993225  --- Iterations:  1896  --- Epochs:  1
 Average loss:  0.007360856048762798  --- Iterations:  1904  --- Epochs:  1
 Average loss:  0.007338781375437975  --- Iterations:  1912  --- Epochs:  1
 Average loss:  0.007323014084249735  --- Iterations:  1920  --- Epochs:  1
 Average loss:  0.007304082624614239  --- Iterations:  1928  --- Epochs:  1
 Average loss:  0.007282129023224115  --- Iterations:  1936  --- Epochs:  1
 Average loss:  0.007264766376465559  --- Iterations:  1944  --- Epochs:  1
 Average loss:  0.0072435038164258  --- Iterations:  1952  --- Epochs:  1
 Average loss:  0.007225761190056801  --- Iterations:  1960  --- Epochs:  1
 Average loss:  0.007203476037830114  --- Iterations:  1968  --- Epochs:  1
 Average loss:  0.007187018170952797  --- Iterations:  1976  --- Epochs:  1
 Average loss:  0.007169094402343035  --- Iterations:  1984  --- Epochs:  1
 Average loss:  0.007151022087782621  --- Iterations:  1992  --- Epochs:  1
 Average loss:  0.007132556289434433  --- Iterations:  2000  --- Epochs:  1
Starting evaluation
Average eval rmse: 52538.38646494202 in 37.550907135009766 seconds
best_prev_rmse 52538.38646494202
Traceback (most recent call last):
  File "enet_sanity.py", line 440, in <module>
    {"best previous evaluaion rmse": best_prev_rmse})
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/wandb/sdk/wandb_run.py", line 1323, in log
    if self.history._step > step:
TypeError: '>' not supported between instances of 'int' and 'dict'