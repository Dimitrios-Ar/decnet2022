torch.Size([8, 3, 352, 608]) torch.Size([8, 1, 352, 608]) torch.Size([8, 1, 352, 608])
normalized_batch_sze torch.Size([8, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
normalized_batch_sze torch.Size([8, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
img_normalizedshape torch.Size([1, 1, 352, 608])
torch.Size([8, 352, 3, 608])
torch.Size([8, 608, 352, 1])
torch.Size([8, 608, 352, 1])
/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
Traceback (most recent call last):
  File "enet_sanity.py", line 346, in <module>
    pred = model(batch_data)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/robotlabx/Desktop/DTAI/decnet2022/src/models/penet2021/penet2021_model.py", line 110, in forward
    d_s2, vm_s2 = self.sparsepooling(d, valid_mask)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/robotlabx/Desktop/DTAI/decnet2022/src/models/penet2021/penet2021_basic.py", line 149, in forward
    d = - self.pooling(encode_d)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/pooling.py", line 164, in forward
    self.return_indices)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/_jit_internal.py", line 405, in fn
    return if_false(*args, **kwargs)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/functional.py", line 718, in _max_pool2d
    return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: Given input size: (608x352x1). Calculated output size: (608x176x0). Output size is too small