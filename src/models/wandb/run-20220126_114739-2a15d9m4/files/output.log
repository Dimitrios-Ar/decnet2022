
 Average loss:  6.251154899597168  --- Iterations:  8  --- Epochs:  1
/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torchvision/transforms/functional.py:165: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)
  img = torch.as_tensor(np.asarray(pic))
/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)
  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)
 Average loss:  5.102630615234375  --- Iterations:  16  --- Epochs:  1
 Average loss:  5.615741729736328  --- Iterations:  24  --- Epochs:  1
 Average loss:  5.384856700897217  --- Iterations:  32  --- Epochs:  1
 Average loss:  5.2912821769714355  --- Iterations:  40  --- Epochs:  1
 Average loss:  5.458247661590576  --- Iterations:  48  --- Epochs:  1
 Average loss:  5.09639310836792  --- Iterations:  56  --- Epochs:  1
 Average loss:  5.241567611694336  --- Iterations:  64  --- Epochs:  1
 Average loss:  5.004458904266357  --- Iterations:  72  --- Epochs:  1
 Average loss:  4.991645336151123  --- Iterations:  80  --- Epochs:  1
 Average loss:  5.398271083831787  --- Iterations:  88  --- Epochs:  1
 Average loss:  5.605599880218506  --- Iterations:  96  --- Epochs:  1
 Average loss:  5.380789756774902  --- Iterations:  104  --- Epochs:  1
 Average loss:  5.2703399658203125  --- Iterations:  112  --- Epochs:  1
 Average loss:  5.095475196838379  --- Iterations:  120  --- Epochs:  1
 Average loss:  5.249646186828613  --- Iterations:  128  --- Epochs:  1
 Average loss:  5.163580894470215  --- Iterations:  136  --- Epochs:  1
 Average loss:  5.21630334854126  --- Iterations:  144  --- Epochs:  1
 Average loss:  5.257638454437256  --- Iterations:  152  --- Epochs:  1
 Average loss:  5.29630184173584  --- Iterations:  160  --- Epochs:  1
 Average loss:  5.385095596313477  --- Iterations:  168  --- Epochs:  1
 Average loss:  5.2326154708862305  --- Iterations:  176  --- Epochs:  1
 Average loss:  5.335129737854004  --- Iterations:  184  --- Epochs:  1
 Average loss:  5.283054828643799  --- Iterations:  192  --- Epochs:  1
 Average loss:  5.230116367340088  --- Iterations:  200  --- Epochs:  1
 Average loss:  5.213832855224609  --- Iterations:  208  --- Epochs:  1
 Average loss:  5.235326290130615  --- Iterations:  216  --- Epochs:  1
 Average loss:  5.285254001617432  --- Iterations:  224  --- Epochs:  1
 Average loss:  5.3134331703186035  --- Iterations:  232  --- Epochs:  1
 Average loss:  5.321144104003906  --- Iterations:  240  --- Epochs:  1
 Average loss:  5.284601211547852  --- Iterations:  248  --- Epochs:  1
 Average loss:  5.267533779144287  --- Iterations:  256  --- Epochs:  1
 Average loss:  5.242532253265381  --- Iterations:  264  --- Epochs:  1
 Average loss:  5.2388482093811035  --- Iterations:  272  --- Epochs:  1
 Average loss:  5.231227397918701  --- Iterations:  280  --- Epochs:  1
 Average loss:  5.191338062286377  --- Iterations:  288  --- Epochs:  1
 Average loss:  5.209807872772217  --- Iterations:  296  --- Epochs:  1
 Average loss:  5.231714725494385  --- Iterations:  304  --- Epochs:  1
 Average loss:  5.189126968383789  --- Iterations:  312  --- Epochs:  1
 Average loss:  5.1714701652526855  --- Iterations:  320  --- Epochs:  1
 Average loss:  5.117474555969238  --- Iterations:  328  --- Epochs:  1
 Average loss:  5.0514092445373535  --- Iterations:  336  --- Epochs:  1
 Average loss:  5.033601760864258  --- Iterations:  344  --- Epochs:  1
 Average loss:  5.065040111541748  --- Iterations:  352  --- Epochs:  1
 Average loss:  5.016988277435303  --- Iterations:  360  --- Epochs:  1
 Average loss:  4.96162748336792  --- Iterations:  368  --- Epochs:  1
 Average loss:  4.940515518188477  --- Iterations:  376  --- Epochs:  1
 Average loss:  4.94133996963501  --- Iterations:  384  --- Epochs:  1
 Average loss:  4.899964809417725  --- Iterations:  392  --- Epochs:  1
 Average loss:  4.902894973754883  --- Iterations:  400  --- Epochs:  1
 Average loss:  4.842110633850098  --- Iterations:  408  --- Epochs:  1
 Average loss:  4.814247131347656  --- Iterations:  416  --- Epochs:  1
 Average loss:  4.75894021987915  --- Iterations:  424  --- Epochs:  1
 Average loss:  4.795444488525391  --- Iterations:  432  --- Epochs:  1
 Average loss:  4.790572643280029  --- Iterations:  440  --- Epochs:  1
 Average loss:  4.762919902801514  --- Iterations:  448  --- Epochs:  1
 Average loss:  4.7371978759765625  --- Iterations:  456  --- Epochs:  1
 Average loss:  4.718625068664551  --- Iterations:  464  --- Epochs:  1
 Average loss:  4.68259859085083  --- Iterations:  472  --- Epochs:  1
 Average loss:  4.642246246337891  --- Iterations:  480  --- Epochs:  1
 Average loss:  4.635481834411621  --- Iterations:  488  --- Epochs:  1
 Average loss:  4.616279602050781  --- Iterations:  496  --- Epochs:  1
 Average loss:  4.630817890167236  --- Iterations:  504  --- Epochs:  1
 Average loss:  4.606387138366699  --- Iterations:  512  --- Epochs:  1
 Average loss:  4.585151195526123  --- Iterations:  520  --- Epochs:  1
 Average loss:  4.6076531410217285  --- Iterations:  528  --- Epochs:  1
 Average loss:  4.6060686111450195  --- Iterations:  536  --- Epochs:  1
 Average loss:  4.608414173126221  --- Iterations:  544  --- Epochs:  1
 Average loss:  4.616876125335693  --- Iterations:  552  --- Epochs:  1
 Average loss:  4.597316741943359  --- Iterations:  560  --- Epochs:  1
 Average loss:  4.58787202835083  --- Iterations:  568  --- Epochs:  1
 Average loss:  4.565536975860596  --- Iterations:  576  --- Epochs:  1
 Average loss:  4.574188709259033  --- Iterations:  584  --- Epochs:  1
 Average loss:  4.566448211669922  --- Iterations:  592  --- Epochs:  1
 Average loss:  4.541928768157959  --- Iterations:  600  --- Epochs:  1
 Average loss:  4.512397766113281  --- Iterations:  608  --- Epochs:  1
 Average loss:  4.497808933258057  --- Iterations:  616  --- Epochs:  1
 Average loss:  4.506877899169922  --- Iterations:  624  --- Epochs:  1
 Average loss:  4.4972310066223145  --- Iterations:  632  --- Epochs:  1
 Average loss:  4.4742560386657715  --- Iterations:  640  --- Epochs:  1
 Average loss:  4.4545979499816895  --- Iterations:  648  --- Epochs:  1
 Average loss:  4.45172643661499  --- Iterations:  656  --- Epochs:  1
 Average loss:  4.471580982208252  --- Iterations:  664  --- Epochs:  1
 Average loss:  4.440728664398193  --- Iterations:  672  --- Epochs:  1
 Average loss:  4.412744045257568  --- Iterations:  680  --- Epochs:  1
 Average loss:  4.431827545166016  --- Iterations:  688  --- Epochs:  1
 Average loss:  4.411734104156494  --- Iterations:  696  --- Epochs:  1
 Average loss:  4.385418891906738  --- Iterations:  704  --- Epochs:  1
 Average loss:  4.370914936065674  --- Iterations:  712  --- Epochs:  1
 Average loss:  4.359993934631348  --- Iterations:  720  --- Epochs:  1
 Average loss:  4.392642498016357  --- Iterations:  728  --- Epochs:  1
 Average loss:  4.4001078605651855  --- Iterations:  736  --- Epochs:  1
 Average loss:  4.386176586151123  --- Iterations:  744  --- Epochs:  1
 Average loss:  4.383316516876221  --- Iterations:  752  --- Epochs:  1
 Average loss:  4.369492053985596  --- Iterations:  760  --- Epochs:  1
 Average loss:  4.393959999084473  --- Iterations:  768  --- Epochs:  1
 Average loss:  4.38629674911499  --- Iterations:  776  --- Epochs:  1
 Average loss:  4.366788864135742  --- Iterations:  784  --- Epochs:  1
 Average loss:  4.3420820236206055  --- Iterations:  792  --- Epochs:  1
 Average loss:  4.340695381164551  --- Iterations:  800  --- Epochs:  1
 Average loss:  4.320578098297119  --- Iterations:  808  --- Epochs:  1
 Average loss:  4.322424411773682  --- Iterations:  816  --- Epochs:  1
 Average loss:  4.307687282562256  --- Iterations:  824  --- Epochs:  1
 Average loss:  4.295313835144043  --- Iterations:  832  --- Epochs:  1
 Average loss:  4.303126811981201  --- Iterations:  840  --- Epochs:  1
 Average loss:  4.296752452850342  --- Iterations:  848  --- Epochs:  1
 Average loss:  4.297845363616943  --- Iterations:  856  --- Epochs:  1
 Average loss:  4.288594722747803  --- Iterations:  864  --- Epochs:  1
 Average loss:  4.2761921882629395  --- Iterations:  872  --- Epochs:  1
 Average loss:  4.255626201629639  --- Iterations:  880  --- Epochs:  1
 Average loss:  4.238590717315674  --- Iterations:  888  --- Epochs:  1
 Average loss:  4.232127666473389  --- Iterations:  896  --- Epochs:  1
 Average loss:  4.230995178222656  --- Iterations:  904  --- Epochs:  1
 Average loss:  4.212516784667969  --- Iterations:  912  --- Epochs:  1
 Average loss:  4.209862232208252  --- Iterations:  920  --- Epochs:  1
 Average loss:  4.202824592590332  --- Iterations:  928  --- Epochs:  1
 Average loss:  4.19992208480835  --- Iterations:  936  --- Epochs:  1
 Average loss:  4.190460681915283  --- Iterations:  944  --- Epochs:  1
 Average loss:  4.188018798828125  --- Iterations:  952  --- Epochs:  1
 Average loss:  4.181485652923584  --- Iterations:  960  --- Epochs:  1
 Average loss:  4.167716026306152  --- Iterations:  968  --- Epochs:  1
 Average loss:  4.158136367797852  --- Iterations:  976  --- Epochs:  1
 Average loss:  4.152122497558594  --- Iterations:  984  --- Epochs:  1
 Average loss:  4.139606475830078  --- Iterations:  992  --- Epochs:  1
 Average loss:  4.127894401550293  --- Iterations:  1000  --- Epochs:  1
 Average loss:  4.110116958618164  --- Iterations:  1008  --- Epochs:  1
 Average loss:  4.09846830368042  --- Iterations:  1016  --- Epochs:  1
 Average loss:  4.096859931945801  --- Iterations:  1024  --- Epochs:  1
 Average loss:  4.081873893737793  --- Iterations:  1032  --- Epochs:  1
 Average loss:  4.069683074951172  --- Iterations:  1040  --- Epochs:  1
 Average loss:  4.0658087730407715  --- Iterations:  1048  --- Epochs:  1
 Average loss:  4.071316242218018  --- Iterations:  1056  --- Epochs:  1
 Average loss:  4.0663933753967285  --- Iterations:  1064  --- Epochs:  1
 Average loss:  4.078941822052002  --- Iterations:  1072  --- Epochs:  1
 Average loss:  4.0808892250061035  --- Iterations:  1080  --- Epochs:  1
 Average loss:  4.082918167114258  --- Iterations:  1088  --- Epochs:  1
 Average loss:  4.082438945770264  --- Iterations:  1096  --- Epochs:  1
 Average loss:  4.0809125900268555  --- Iterations:  1104  --- Epochs:  1
 Average loss:  4.080171585083008  --- Iterations:  1112  --- Epochs:  1
 Average loss:  4.07371187210083  --- Iterations:  1120  --- Epochs:  1
 Average loss:  4.069015979766846  --- Iterations:  1128  --- Epochs:  1
 Average loss:  4.052065372467041  --- Iterations:  1136  --- Epochs:  1
 Average loss:  4.042848110198975  --- Iterations:  1144  --- Epochs:  1
 Average loss:  4.041317939758301  --- Iterations:  1152  --- Epochs:  1
 Average loss:  4.03070592880249  --- Iterations:  1160  --- Epochs:  1
 Average loss:  4.024471282958984  --- Iterations:  1168  --- Epochs:  1
 Average loss:  4.013756275177002  --- Iterations:  1176  --- Epochs:  1
 Average loss:  4.016722679138184  --- Iterations:  1184  --- Epochs:  1
 Average loss:  4.007497787475586  --- Iterations:  1192  --- Epochs:  1
 Average loss:  4.008112907409668  --- Iterations:  1200  --- Epochs:  1
 Average loss:  4.002810478210449  --- Iterations:  1208  --- Epochs:  1
 Average loss:  4.002842426300049  --- Iterations:  1216  --- Epochs:  1
 Average loss:  3.989138603210449  --- Iterations:  1224  --- Epochs:  1
 Average loss:  3.9967775344848633  --- Iterations:  1232  --- Epochs:  1
 Average loss:  3.9909820556640625  --- Iterations:  1240  --- Epochs:  1
 Average loss:  3.9758598804473877  --- Iterations:  1248  --- Epochs:  1
 Average loss:  3.967773199081421  --- Iterations:  1256  --- Epochs:  1
 Average loss:  3.956101417541504  --- Iterations:  1264  --- Epochs:  1
 Average loss:  3.952566385269165  --- Iterations:  1272  --- Epochs:  1
 Average loss:  3.9430510997772217  --- Iterations:  1280  --- Epochs:  1
 Average loss:  3.9327614307403564  --- Iterations:  1288  --- Epochs:  1
 Average loss:  3.9566903114318848  --- Iterations:  1296  --- Epochs:  1
 Average loss:  3.9557576179504395  --- Iterations:  1304  --- Epochs:  1
 Average loss:  3.9573872089385986  --- Iterations:  1312  --- Epochs:  1
 Average loss:  3.9506454467773438  --- Iterations:  1320  --- Epochs:  1
 Average loss:  3.955709934234619  --- Iterations:  1328  --- Epochs:  1
 Average loss:  3.9470083713531494  --- Iterations:  1336  --- Epochs:  1
 Average loss:  3.942023277282715  --- Iterations:  1344  --- Epochs:  1
 Average loss:  3.9359376430511475  --- Iterations:  1352  --- Epochs:  1
 Average loss:  3.926136016845703  --- Iterations:  1360  --- Epochs:  1
 Average loss:  3.923346757888794  --- Iterations:  1368  --- Epochs:  1
 Average loss:  3.913064956665039  --- Iterations:  1376  --- Epochs:  1
 Average loss:  3.90297269821167  --- Iterations:  1384  --- Epochs:  1
 Average loss:  3.904507637023926  --- Iterations:  1392  --- Epochs:  1
 Average loss:  3.9083337783813477  --- Iterations:  1400  --- Epochs:  1
 Average loss:  3.906599998474121  --- Iterations:  1408  --- Epochs:  1
 Average loss:  3.8981757164001465  --- Iterations:  1416  --- Epochs:  1
 Average loss:  3.8902013301849365  --- Iterations:  1424  --- Epochs:  1
 Average loss:  3.8845009803771973  --- Iterations:  1432  --- Epochs:  1
 Average loss:  3.888378381729126  --- Iterations:  1440  --- Epochs:  1
 Average loss:  3.887572765350342  --- Iterations:  1448  --- Epochs:  1
 Average loss:  3.881136417388916  --- Iterations:  1456  --- Epochs:  1
 Average loss:  3.8758466243743896  --- Iterations:  1464  --- Epochs:  1
 Average loss:  3.8698370456695557  --- Iterations:  1472  --- Epochs:  1
 Average loss:  3.8656466007232666  --- Iterations:  1480  --- Epochs:  1
 Average loss:  3.8648061752319336  --- Iterations:  1488  --- Epochs:  1
 Average loss:  3.8549177646636963  --- Iterations:  1496  --- Epochs:  1
 Average loss:  3.870866060256958  --- Iterations:  1504  --- Epochs:  1
 Average loss:  3.8650577068328857  --- Iterations:  1512  --- Epochs:  1
 Average loss:  3.861389398574829  --- Iterations:  1520  --- Epochs:  1
 Average loss:  3.8535773754119873  --- Iterations:  1528  --- Epochs:  1
 Average loss:  3.8493096828460693  --- Iterations:  1536  --- Epochs:  1
 Average loss:  3.841228485107422  --- Iterations:  1544  --- Epochs:  1
 Average loss:  3.8386402130126953  --- Iterations:  1552  --- Epochs:  1
 Average loss:  3.8355841636657715  --- Iterations:  1560  --- Epochs:  1
 Average loss:  3.8289356231689453  --- Iterations:  1568  --- Epochs:  1
 Average loss:  3.8240225315093994  --- Iterations:  1576  --- Epochs:  1
 Average loss:  3.8270821571350098  --- Iterations:  1584  --- Epochs:  1
 Average loss:  3.8229925632476807  --- Iterations:  1592  --- Epochs:  1
 Average loss:  3.8198118209838867  --- Iterations:  1600  --- Epochs:  1
 Average loss:  3.8207690715789795  --- Iterations:  1608  --- Epochs:  1
 Average loss:  3.821824073791504  --- Iterations:  1616  --- Epochs:  1
 Average loss:  3.81754469871521  --- Iterations:  1624  --- Epochs:  1
 Average loss:  3.812631368637085  --- Iterations:  1632  --- Epochs:  1
 Average loss:  3.8034095764160156  --- Iterations:  1640  --- Epochs:  1
 Average loss:  3.794720411300659  --- Iterations:  1648  --- Epochs:  1
 Average loss:  3.785600185394287  --- Iterations:  1656  --- Epochs:  1
 Average loss:  3.782287359237671  --- Iterations:  1664  --- Epochs:  1
 Average loss:  3.779369354248047  --- Iterations:  1672  --- Epochs:  1
 Average loss:  3.7710297107696533  --- Iterations:  1680  --- Epochs:  1
 Average loss:  3.767012357711792  --- Iterations:  1688  --- Epochs:  1
 Average loss:  3.7650434970855713  --- Iterations:  1696  --- Epochs:  1
 Average loss:  3.760478973388672  --- Iterations:  1704  --- Epochs:  1
 Average loss:  3.749328851699829  --- Iterations:  1712  --- Epochs:  1
 Average loss:  3.743908405303955  --- Iterations:  1720  --- Epochs:  1
 Average loss:  3.739903450012207  --- Iterations:  1728  --- Epochs:  1
 Average loss:  3.734384298324585  --- Iterations:  1736  --- Epochs:  1
 Average loss:  3.7324843406677246  --- Iterations:  1744  --- Epochs:  1
 Average loss:  3.725400686264038  --- Iterations:  1752  --- Epochs:  1
 Average loss:  3.7224230766296387  --- Iterations:  1760  --- Epochs:  1
 Average loss:  3.7214131355285645  --- Iterations:  1768  --- Epochs:  1
 Average loss:  3.7183008193969727  --- Iterations:  1776  --- Epochs:  1
 Average loss:  3.7234413623809814  --- Iterations:  1784  --- Epochs:  1
 Average loss:  3.7266829013824463  --- Iterations:  1792  --- Epochs:  1
 Average loss:  3.7183055877685547  --- Iterations:  1800  --- Epochs:  1
 Average loss:  3.712966203689575  --- Iterations:  1808  --- Epochs:  1
 Average loss:  3.711866617202759  --- Iterations:  1816  --- Epochs:  1
 Average loss:  3.7049567699432373  --- Iterations:  1824  --- Epochs:  1
 Average loss:  3.6979312896728516  --- Iterations:  1832  --- Epochs:  1
 Average loss:  3.697312355041504  --- Iterations:  1840  --- Epochs:  1
 Average loss:  3.699603796005249  --- Iterations:  1848  --- Epochs:  1
 Average loss:  3.693079710006714  --- Iterations:  1856  --- Epochs:  1
 Average loss:  3.685063362121582  --- Iterations:  1864  --- Epochs:  1
 Average loss:  3.6850292682647705  --- Iterations:  1872  --- Epochs:  1
 Average loss:  3.6795244216918945  --- Iterations:  1880  --- Epochs:  1
 Average loss:  3.6737847328186035  --- Iterations:  1888  --- Epochs:  1
 Average loss:  3.672187566757202  --- Iterations:  1896  --- Epochs:  1
 Average loss:  3.6691184043884277  --- Iterations:  1904  --- Epochs:  1
 Average loss:  3.6621158123016357  --- Iterations:  1912  --- Epochs:  1
 Average loss:  3.6620357036590576  --- Iterations:  1920  --- Epochs:  1
 Average loss:  3.6579203605651855  --- Iterations:  1928  --- Epochs:  1
 Average loss:  3.651317596435547  --- Iterations:  1936  --- Epochs:  1
 Average loss:  3.6497702598571777  --- Iterations:  1944  --- Epochs:  1
 Average loss:  3.643118143081665  --- Iterations:  1952  --- Epochs:  1
 Average loss:  3.6406447887420654  --- Iterations:  1960  --- Epochs:  1
 Average loss:  3.6331419944763184  --- Iterations:  1968  --- Epochs:  1
 Average loss:  3.6319732666015625  --- Iterations:  1976  --- Epochs:  1
Traceback (most recent call last):
  File "enet_sanity.py", line 372, in <module>
    trace_model = torch.jit.trace(model,save_batch)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/jit/_trace.py", line 744, in trace
    _module_class,
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/jit/_trace.py", line 959, in trace_module
    argument_names,
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/robotlabx/anaconda3/envs/pytorchenv/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1039, in _slow_forward
    result = self.forward(*input, **kwargs)
  File "/home/robotlabx/Desktop/DTAI/decnet2022/src/models/penet2021/penet2021_model.py", line 73, in forward
    d = input['d']
KeyError: 'd'
 Average loss:  3.628476619720459  --- Iterations:  1984  --- Epochs:  1
 Average loss:  3.6243550777435303  --- Iterations:  1992  --- Epochs:  1
 Average loss:  3.619243621826172  --- Iterations:  2000  --- Epochs:  1
saving model and weights at  <built-in method item of Tensor object at 0x7fab38c9f6c0> 2000 1